{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "597db86a-8d55-40ad-97d3-b48197f8474b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module(\n",
      "  (layer1): Linear(in_features=4, out_features=3, bias=True)\n",
      ")\n",
      "Input: tensor([[0.9017, 0.4572, 1.3625, 1.6010]])\n",
      "Output: tensor([[0.0918, 0.0000, 0.0000]], grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class module(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(module, self).__init__()\n",
    "        self.layer1 = nn.Linear(4, 3) \n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = F.relu(x)\n",
    "        return x\n",
    "\n",
    "model = module()\n",
    "print(model)\n",
    "input = torch.randn(1,4)\n",
    "output = model(input)\n",
    "print(\"Input:\", input)\n",
    "print(\"Output:\", output)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d537ec8-1e6a-41e3-926a-2fc1da332829",
   "metadata": {},
   "source": [
    "# Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d054cdf-4e17-4893-ac0a-64d6b42422d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Loss: 0.09814180433750153\n",
      "New Loss : 0.09792007505893707\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "class update(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(update, self).__init__()\n",
    "        self.l1 = nn.Linear(4, 3)  \n",
    "        self.l2 = nn.Linear(3, 2)  \n",
    "        self.l3 = nn.Linear(2, 1)  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.l1(x))  \n",
    "        x = torch.relu(self.l2(x)) \n",
    "        x = self.l3(x)              \n",
    "        return x\n",
    "\n",
    "model = update()\n",
    "criterion = nn.MSELoss() \n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01) \n",
    "\n",
    "input_data = torch.randn(5, 4) \n",
    "target = torch.randn(5, 1)     \n",
    "\n",
    "output = model(input_data)\n",
    "loss = criterion(output, target)\n",
    "print('Initial Loss:', loss.item())\n",
    "optimizer.zero_grad()   \n",
    "loss.backward()        \n",
    "\n",
    "optimizer.step()       \n",
    "output = model(input_data)\n",
    "new_loss = criterion(output, target)\n",
    "print('New Loss :', new_loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834bfd03-449e-4fa6-97d6-a6300263e9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "# Step 1: Fetch the dataset\n",
    "car_evaluation = fetch_ucirepo(id=19)\n",
    "X = car_evaluation.data.features\n",
    "y = car_evaluation.data.targets.values.flatten()  # Convert to 1D array\n",
    "\n",
    "# Step 2: Preprocess the data\n",
    "# Convert categorical variables to numeric\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "y = pd.factorize(y)[0]  # Encode target labels\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_tensor = torch.FloatTensor(X.values)\n",
    "y_tensor = torch.LongTensor(y)\n",
    "\n",
    "# Step 3: Define the model\n",
    "class SimpleNN(nn.Module):\n",
    "    def _init_(self):\n",
    "        super(SimpleNN, self)._init_()\n",
    "        self.input_layer = nn.Linear(X_tensor.shape[1], 3)  # Input layer\n",
    "        self.hidden1 = nn.Linear(3, 2)  # First hidden layer\n",
    "        self.hidden2 = nn.Linear(2, 1)  # Second hidden layer (Output layer)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.input_layer(x))\n",
    "        x = F.relu(self.hidden1(x))\n",
    "        x = self.hidden2(x)  # Output layer\n",
    "        return x\n",
    "\n",
    "# Step 4: Initialize the model, loss function, and optimizer\n",
    "model = SimpleNN()\n",
    "criterion = nn.BCEWithLogitsLoss()  # Binary Cross Entropy with logits (for binary classification)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Step 5: Train the model\n",
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    \n",
    "    # Forward pass\n",
    "    outputs = model(X_tensor).squeeze()  # Remove unnecessary dimensions\n",
    "    loss = criterion(outputs, y_tensor.float())\n",
    "\n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()  # Zero gradients\n",
    "    loss.backward()        # Backpropagation\n",
    "    optimizer.step()       # Update parameters\n",
    "\n",
    "    if (epoch + 1) % 100 == 0:  # Print every 100 epochs\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Test the model (optional)\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    predicted = (torch.sigmoid(model(X_tensor).squeeze()) > 0.5).float()\n",
    "    accuracy = (predicted == y_tensor.float()).float().mean()\n",
    "    print(f'Accuracy: {accuracy:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
